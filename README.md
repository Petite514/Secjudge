# SecJudge

> **An open-source framework for secure and verifiable LLM-as-a-judge services**

SecJudge is a pioneering platform designed for **secure and verifiable evaluation of large language models (LLMs)**, enabling researchers and developers to assess LLM outputs while protecting sensitive prompts and ensuring ownership verification. It leverages **differential privacy** and **clean-label watermarking** to balance privacy, utility, and detectability in LLM-as-a-judge scenarios.

## âœ¨ Key Features

- **Secure Prompt Obfuscation**: Implements the ISÂ²-DP scheme for intra-sentence and inter-sentence shielding, protecting sensitive prompts using differential privacy.
- **Ownership Verification**: Employs clean-label watermarking with an optimized t-test detection protocol to identify unauthorized use of evaluation queries.
- **Unified Evaluation Pipeline**: Supports evaluation of LLMs across benchmark datasets (IMDb, SST-5, Yelp) with metrics like accuracy, FrÃ©chet Inception Distance (FID), and F1 Score.

## ğŸ’¾ Installation

```bash
git clone https://github.com/wenxiwu514/SecJudge.git
cd SecJudge

# (Optional) create a virtual environment
python -m venv .venv && source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

Core dependencies: `torch`, `transformers`, `sentence_transformers`.

## ğŸš€ Quick Start

### 1. Generate Obfuscated Evaluation Queries

```bash
python main.py \
    --api hf \
    --dataset sst5 \
    --data_file data/sst5/sst5_test.csv \
    --word_embedding_model distilbert-base-uncased \
    --phrase_model Qwen/Qwen2.5-1.5B-Instruct \
    --combine_divide 4 \
    --epochs 1 \
    --num_private_samples 10 \
    --result_folder result \
    --feature_extractor_batch_size 1024 \
    --feature_extractor all-mpnet-base-v2 \
    --noise_multiplier 0 \
    --nn_mode L2 \
    --count_threshold 0.0 \
    --select_syn_mode rank \
    --save_syn_mode selected \
    --model_name Qwen/Qwen2.5-1.5B-Instruct \
    --variation_batch_size 128 \
    --length 128
python watermarking.py \
# Please change the parameters in the script.sh file to generate different queries
```

This command applies the ISÂ²-DP scheme to generate obfuscated queries with embedded watermarks.

### 2. Watermark Detection

```bash
python t-test.py \
```

### 3. Evaluate LLM Performance

```bash
python evaluation.py \
  --api_key "your_api_key" \
  --base_url "your_base_url" \
  --path "path/to/querysets" \
  --model "model_to_evaluate" \
```



## ğŸ—‚ï¸ Project Layout

```
SecJudge/
â”œâ”€â”€ scripts/              # Scripts for query generation, evaluation, and watermark detection
â”‚   â””â”€â”€ issdp.py
â”œâ”€â”€ data/                 # Benchmark datasets (IMDb, SST-5, Yelp)
â”œâ”€â”€ utils/                # Tools for differential privacy and watermarking
â”œâ”€â”€ t-test.py             # Watermark detection script
â”œâ”€â”€ evaluation.py         # Unified evaluation script
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```



## ğŸ“œ License

SecJudge is released under the MIT License. See the `LICENSE` file for details.

## ğŸ“ Contact

For questions, please open an issue on [GitHub](https://github.com/wenxiwu514/Secjudge/issues).
